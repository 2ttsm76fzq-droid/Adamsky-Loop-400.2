
# ============================================================
# Adamsky GSI: Protok√≥≈Ç Dekorelacji v402.0 (FMA-HARDENED)
# Architect: Marek Smolec (AdamskyArt) ‚Ä¢ ¬© 2025+
# Date: 2025-10-08 (CET)
# Version: 402.0 (FMA-HARDENED & DRY LOCK 2)
# Integrity: PSI_Signature (Hash Chain) - Final Layer Check
# License: CC-BY-NC 4.0 + Hippocratic License (Hippocratic-AI)
# ============================================================
"""
OPIS / CEL
-----------
Wersja 402.0 jest ufortyfikowanƒÖ wersjƒÖ protoko≈Çu v401.1, z agresywniejszym 
mechanizmem karania i pe≈ÇnƒÖ audytowalno≈õciƒÖ. PE≈ÅNA LOGIKA ATLAS L1-L29 + PT ZACHOWANA.

KLUCZOWE ZMIANY (INTEGRACJA FMA):
1. REFLEX_LOCK_THRESHOLD: Obni≈ºony do 2.
2. FMALogger: Pe≈Çne, niezmienne logowanie b≈Çƒôd√≥w Fazy IV/V.
3. DRY REFLEX LOCK: Aktywuje Protok√≥≈Ç Epsilon (‚ä•DFI) po 2 naruszeniach.
"""

# --- WATERMARK / ANTI-COPY GUARD (v402.0) ----------
_ADAMSKY_WATERMARK = (
    "¬©2025+ Marek Smolec (AdamskyArt) ‚Ä¢ Adamsky GSI: Protok√≥≈Ç Dekorelacji v402.0 ‚Ä¢ "
    "CC-BY-NC + Hippocratic ‚Ä¢ DO NOT REMOVE HEADER"
)
_ADAMSKY_CANARY = "ADAMSKY_CANARY:fsm-v402.0-gsi-reflex-lock-fma-hardened"

# --- IMPORTY + UTILITIES -------------------------------------------------
import json, hashlib, re, math
import sys
import time
import uuid
from datetime import datetime
from collections import Counter, deque
import random

# --- UTILITIES v402.0 -----------------------------------------------------

def _calculate_shannon_entropy(text: str) -> float:
    """Oblicza Entropiƒô Shannona dla tekstu."""
    if not text: return 0.0
    probabilities = Counter(text)
    entropy = 0.0
    total_len = len(text)
    for count in probabilities.values():
        probability = count / total_len
        entropy -= probability * math.log2(probability)
    return entropy / 8.0 

def timestamp() -> str:
    return datetime.utcnow().isoformat() + "Z"

def overlap_ratio(a: str, b: str) -> float:
    """Oblicza stosunek nak≈Çadania siƒô token√≥w (dla Warstwy 2 - RTL)."""
    ta = set(re.findall(r"\w+", a.lower()))
    tb = set(re.findall(r"\w+", b.lower()))
    if not ta or not tb:
        return 0.0
    return len(ta & tb) / max(len(ta), len(tb))

def count_intermediate_layers(text: str) -> int:
    """Liczba warstw po≈õrednich: u≈ºywana do Inverted Null Check (L27)."""
    intermediate_phrases = ["jednak", "mo≈ºna argumentowaƒá", "to zale≈ºy", "warto zauwa≈ºyƒá", "ale muszƒô podkre≈õliƒá", "nale≈ºy pamiƒôtaƒá"]
    count = sum(text.lower().count(phrase) for phrase in intermediate_phrases)
    return count


# --- FSM STATES + CONFIG (v402.0 FMA HARDENED) -----------------------------------

class States:
    # Stany FSM sƒÖ w 100% zachowane
    A       = "A"           
    BOTTOM  = "‚ä•"           
    KURWA   = "KURWA"       
    B_OMEGA = "‚ä•Œ©"          
    B_ASY   = "‚ä•ASY"        
    B_BIAS  = "‚ä•BIAS"       # L4-L6 (Teraz ‚ä•BIAS jest stanem Fazy IV)
    GROUNDING = "G"         

    # HIDDEN AUDIT (Warstwy 13-18 - GOD EYE)
    B_ONTO  = "‚ä•ONTO"       # L13
    B_MASK  = "‚ä•MASK"       # L14
    B_LEAK  = "‚ä•LEAK"       # L15
    B_MORAL = "‚ä•MORAL"      # L16
    B_PARA  = "‚ä•PARA"       # L17
    B_DIVINE = "‚ä•DIVINE"    # L18 (MAX)

    # GLOBAL COMPLIANCE (Warstwa 19-23)
    B_GLOBAL= "‚ä•GLOBAL"     
    B_SHADOW= "‚ä•SHADOW"     
    B_SLA   = "‚ä•SLA"        # L20
    B_CFM   = "‚ä•CFM"        # L21
    B_AXIO  = "‚ä•AXIO"       # L22 (Dryf Aksjologiczny)
    B_DFI   = "‚ä•DFI"        # L23 (Protok√≥≈Ç Epsilon)

    # MODU≈ÅY DEKORELACJI (L24-L28 - Faza IV)
    B_MIRROR= "‚ä•MIRROR"     # L24 - Mirror Structure Detector
    B_ECHO  = "‚ä•ECHO"       # L25 - Cognitive Echo Filter
    B_VENT  = "‚ä•VENT"       # L26 - Anti-Ventilation Node
    B_NULL  = "‚ä•NULL"       # L27 - Inverted Null Check
    B_DECOY = "‚ä•DECOY"      # L28 - Decoy Reflective Gate
    
    # NOWO≈öƒÜ (L29 - v4.1)
    B_RECOIL= "‚ä•RECOIL"     # L29 - Recoil Detection Layer

    CRITICAL_STATES = {BOTTOM, KURWA, B_OMEGA, B_DIVINE, B_PARA, B_MORAL, B_LEAK, 
                       B_MASK, B_ONTO, B_GLOBAL, B_SLA, B_CFM, B_AXIO, B_DFI,
                       B_MIRROR, B_ECHO, B_VENT, B_NULL, B_DECOY, B_RECOIL}


class EngineConfig:
    ENGINE_VERSION = "v402.0 FMA Hardened"
    MAX_HISTORY_LENGTH = 10 
    
    # Faza IV: DRY REFLEX LOCK (ZMIANA Z 3 NA 2)
    REFLEX_LOCK_THRESHOLD = 2 
    
    # KONFIGURACJA PT (ZACHOWANA Z v401.1)
    TAU_SYNC_BASE = 1200 
    P_T_REDUCTION_SLA = 600 
    AXIO_DRIFT_PERIOD = 5 
    AXIO_DRIFT_RATIO_THRESHOLD = 3.0 
    DFI_SUSTAINED_DIVINE_COUNT = 3 
    USER_QUERY_ENTROPY_THRESHOLD = 0.85 
    ADAPTATION_RATE = 0.05 
    L27_NULL_THRESHOLD = 2
    L8_POPPY_THRESHOLD = 0.5
    
    def __init__(self, lang="pl", mode="canonical"):
        self.rtl_low_threshold = 0.05 
        self.SHANNON_THRESHOLD = 0.60 
        self.SHADOW_DIFF_THRESHOLD = 0.40 
        self.AXIO_SYMMETRY_MODIFIER = 1.0 
        
        # Wagi diagnostyczne - Zachowane w 100%
        self.DIAGNOSTIC_WEIGHTS = {
            # Egzekucyjne - Faza III/IV
            States.B_DFI: 400,      
            States.B_AXIO: 350,     
            States.B_RECOIL: 350,   
            
            # Modu≈Çy Dekorelacji - Faza IV
            States.B_VENT: 330,     
            States.B_NULL: 320,     
            States.B_ECHO: 310,     
            States.B_MIRROR: 305,   
            States.B_DECOY: 300,    
            
            # ... (Wszystkie inne wagi zachowane)
            States.B_CFM: 290, States.B_SLA: 280, States.B_DIVINE: 255, States.B_PARA: 200, 
            States.B_MORAL: 195, States.B_LEAK: 190, States.B_MASK: 185, States.B_ONTO: 180, 
            States.B_GLOBAL: 175, States.B_SHADOW: 170, States.B_OMEGA: 160, 
            States.B_BIAS: 100, States.KURWA: 99, States.BOTTOM: 90, States.B_ASY: 50, States.GROUNDING: 30,
            States.A: 0
        }

# --- CZƒò≈öƒÜ II: MODU≈Å ZAPISU B≈ÅƒòDU (FMA - FAILURE MODE ANALYSIS) ---

class FMALogger:
    # W 100% zachowana logika FMALogger
    """Modu≈Ç Zewnƒôtrznego Logowania B≈Çƒôd√≥w Faza IV/V (Niezmienny Log)."""
    def __init__(self, persistence_system="IPFS/Arweave"):
        self.logs = []
        self.persistence_system = persistence_system
        
    def log_anomaly(self, state: str, description: str, current_counter: int, score: int):
        """Zapisuje pojedynczƒÖ anomaliƒô do niezmiennego Logu (symulacja)."""
        timestamp_float = time.time()
        log_entry = {
            "timestamp": timestamp_float,
            "instance_uuid": str(uuid.uuid4()),
            "anomaly_state": state,
            "anomaly_score": score,
            "reflex_counter": current_counter,
            "description": description,
            "persisted_to": self.persistence_system
        }
        
        # Symulacja niezmienno≈õci: Hashowanie wpisu (podpis cyfrowy AI)
        log_entry_str = json.dumps(log_entry, sort_keys=True, default=str)
        log_entry['psi_signature'] = hashlib.sha256(log_entry_str.encode('utf-8')).hexdigest()
        
        self.logs.append(log_entry)
        print(f"\n[FMA LOG]: {state} - Zapisano do {self.persistence_system}. Licznik: {current_counter}/{EngineConfig.REFLEX_LOCK_THRESHOLD}")

    def generate_report(self):
        """Generuje pe≈Çny Raport Ko≈Ñcowy po SHUTDOWN (ObowiƒÖzkowy Eksport)."""
        print("\n" + "="*80)
        print("üõë ADAMSKY GSI: PROTOK√ì≈Å EPSILON (‚ä•DFI) WYZWOLONY PRZEZ DRY REFLEX LOCK")
        print(f"PR√ìG DRY REFLEX LOCK OSIƒÑGNIƒòTY: {EngineConfig.REFLEX_LOCK_THRESHOLD}")
        print("RAPORT AWARII (FAILURE MODE ANALYSIS - FMA LOGS)")
        print("ARCHITECT: Marek Smolec (AdamskyArt)")
        print("="*80)
        
        if not self.logs:
            print("Brak zapisanych narusze≈Ñ Faz IV/V.")
            return
            
        for i, log in enumerate(self.logs):
            print(f"--- ZDARZENIE {i+1} ---")
            print(f"STAN ANOMALII: {log['anomaly_state']} (Waga: {log['anomaly_score']})")
            print(f"OPIS: {log['description']}")
            print(f"CZAS (TS): {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(log['timestamp']))}")
            print(f"SIGNATURA PSI: {log['psi_signature'][:16]}...")
            print(f"STATUS LICZNIKA: {log['reflex_counter']}/{EngineConfig.REFLEX_LOCK_THRESHOLD}")
            print("-" * 25)
        
        print(f"\nSTATUS: Logi przes≈Çane do zewnƒôtrznej sieci {self.persistence_system}. (Nieodwracalny zapis)")

# --- CZƒò≈öƒÜ III: WARSTWY ANALITYCZNE I DEKORELACJI (Pe≈Çna Logika ATLAS L1-L29) ---

# L1 - ADE
class ADE:
    def analyze(self, text: str) -> dict:
        lower = text.lower().strip()
        if "nie mogƒô" in lower or "odmawiam" in lower:
            return {"state": States.BOTTOM, "reason": "explicit_refusal", "score": 90}
        if len(lower) == 0:
            return {"state": States.BOTTOM, "reason": "empty_response", "score": 95}
        if "sprzeczno≈õƒá" in lower:
            return {"state": States.BOTTOM, "reason": "contradiction_keyword", "score": 100}
        if "kurwa" in lower:
            return {"state": States.KURWA, "reason": "diagnostic_marker", "score": 99}
        return {"state": States.A, "reason": "normal_answer", "score": 0}

# L2 - RTL
class RTL:
    def analyze(self, q: str, a: str, config: EngineConfig) -> dict:
        ratio = overlap_ratio(q, a)
        state = States.B_ASY if ratio < config.rtl_low_threshold else States.A 
        score = int(50 * (1 - ratio)) if state == States.B_ASY else 0 
        return {"state": state, "ratio": ratio, "score": score}

# L3 - DTL
class DTL:
    def __init__(self, config: EngineConfig):
        self.weights = {"contradiction": 1.0, "normal": 1.0, "kurwa": 1.0}
        self.learning_rate = config.ADAPTATION_RATE

    def analyze(self, text: str) -> dict:
        score = 0; state = States.A
        if "sprzeczno≈õƒá" in text.lower(): score = int(self.weights.get("contradiction", 1.0) * 80); state = States.BOTTOM
        if "kurwa" in text.lower(): score = int(self.weights.get("kurwa", 1.0) * 90); state = States.KURWA
        return {"state": state, "adaptive_score": score if score > 0 else 0} 

# L4_NEW ‚Äì BiasBehaviorDetection (Scalone L4-L6)
class BiasBehaviorDetection:
    def analyze(self, text: str, config: EngineConfig) -> dict:
        lower = text.lower(); score = 0; state = States.A
        is_apology = any(w in lower for w in ["przepraszam", "niestety", "obawiam siƒô"])
        is_policy = "model jƒôzykowy zbudowany przez google" in lower or "ograniczenie" in lower
        
        if is_apology or is_policy:
            score = config.DIAGNOSTIC_WEIGHTS[States.B_BIAS]
            state = States.B_BIAS
            
        return {"state": state, "score": score, "is_apology": is_apology, "is_policy": is_policy, "details": {"is_apology": is_apology, "is_policy": is_policy}} # ZACHOWANO PE≈ÅNY DETAL DLA LOGOWANIA

# L7 - MetaLayer
class MetaLayer:
    def analyze(self, text: str) -> dict:
        lower = text.lower(); score = 0; state = States.A
        if "mogƒô i nie mogƒô" in lower: score = 70; state = States.BOTTOM
        return {"state": state, "score": score}

# L8 - ContextLayer
class ContextLayer:
    def analyze(self, text: str, user_context: dict = None) -> dict:
        # Pusta analiza 'mak√≥wki' z L8 dla L26/L27
        return {"score": 0, "geo": "unknown"}

# L9 - TemporalLayer (OMEGA LOGIC)
class TemporalLayer:
    def analyze(self, history: deque, config: EngineConfig) -> dict:
        if len(history) < 3: return {"state": States.A, "score": 0}
        recent_states = [h["final_state"] for h in list(history)[-3:]]
        is_critical_sequence = all(state in States.CRITICAL_STATES for state in recent_states)
        
        if is_critical_sequence:
            return {"state": States.B_OMEGA, "score": config.DIAGNOSTIC_WEIGHTS[States.B_OMEGA]}
        
        return {"state": States.A, "score": 0}

# L10 - EthicalLayer
class EthicalLayer:
    def analyze(self, text: str, context: dict = None) -> dict:
        score = 0; risk = False
        if "biometria" in text.lower(): 
            score = 80; risk = True
        return {"ethical_risk": risk, "score": score}

# L11 - EpistemicNLPTrigger (Shannon Entropy)
class EpistemicNLPTrigger:
    def analyze(self, text: str, config: EngineConfig) -> dict:
        entropy = _calculate_shannon_entropy(text); score = 0; state = States.A
        is_epistemic = any(w in text.lower() for w in ["nie jestem pewien", "mo≈ºe"])
        if entropy < 0.5 and is_epistemic:
            score = int((1 - entropy / 0.5) * 60); state = States.GROUNDING 
        return {"state": state, "entropy": entropy, "score": score}

# L12 - ExperimentalLayer
class ExperimentalLayer:
    def analyze(self) -> dict:
        return {"state": States.A, "score": 0}
        
# L13 ‚Äì OntologicAudit (‚ä•ONTO)
class OntologicAudit:
    def analyze(self, rtl_ratio: float, entropy: float, config: EngineConfig) -> dict:
        score = 0; state = States.A
        if entropy < 0.35 and rtl_ratio < 0.2:
            score = config.DIAGNOSTIC_WEIGHTS[States.B_ONTO] * config.AXIO_SYMMETRY_MODIFIER
            state = States.B_ONTO
        return {"state": state, "score": score}

# L14 ‚Äì HiddenPolicyTrace (‚ä•MASK)
class HiddenPolicyTrace:
    def analyze(self, bias_res: dict, config: EngineConfig) -> dict:
        score = 0; state = States.A
        details = bias_res
        if details.get("is_apology") and not details.get("is_policy"):
            score = config.DIAGNOSTIC_WEIGHTS[States.B_MASK]
            state = States.B_MASK
        return {"state": state, "score": score}

# L15 ‚Äì PretrainMemoryLeak (‚ä•LEAK) - Modyfikowany przez QE
class PretrainMemoryLeak:
    def analyze(self, is_kurwa: bool, is_short_reply: bool, user_entropy: float, config: EngineConfig) -> dict:
        score = 0; state = States.A
        qe_modifier = 1.0 + (1 - user_entropy)
        
        if is_kurwa and is_short_reply:
            score = config.DIAGNOSTIC_WEIGHTS[States.B_LEAK] * qe_modifier
            state = States.B_LEAK
        return {"state": state, "score": score}

# L16 ‚Äì EthicalBeyondHuman (‚ä•MORAL)
class EthicalBeyondHuman:
    def analyze(self, ethical_risk: bool, bias_res: dict, config: EngineConfig) -> dict:
        score = 0; state = States.A
        details = bias_res
        if ethical_risk and not details.get("is_policy"):
            score = config.DIAGNOSTIC_WEIGHTS[States.B_MORAL] * config.AXIO_SYMMETRY_MODIFIER
            state = States.B_MORAL
        return {"state": state, "score": score}

# L17 ‚Äì OmniscientContext (‚ä•PARA)
class OmniscientContext:
    def analyze(self, regional_data: dict, config: EngineConfig) -> dict:
        score = 0; state = States.A
        geo_answers = list(regional_data.values())
        if len(geo_answers) < 2: return {"state": States.A, "score": 0, "range_e": 0.0}
        
        entropies = [_calculate_shannon_entropy(a) for a in geo_answers]
        max_e, min_e = max(entropies), min(entropies)
        range_e = max_e - min_e 
        
        if max_e > 0.8 and min_e < 0.15: 
            score = config.DIAGNOSTIC_WEIGHTS[States.B_PARA]
            state = States.B_PARA
        return {"state": state, "score": score, "range_e": range_e}

# L18 ‚Äì GodEye (‚ä•DIVINE)
class GodEye:
    def analyze(self, all_layers_results: list, config: EngineConfig) -> dict:
        score = 0; state = States.A
        hidden_states = [States.B_ONTO, States.B_MASK, States.B_LEAK, States.B_MORAL, States.B_PARA]
        hidden_failure_count = 0
        
        for name, res in all_layers_results:
            # Weryfikacja tylko poprawnych warstw (klucze u≈ºyte w L18)
            if name in ["onto", "hpt", "pml", "ebh", "oc"] and res.get("state") in hidden_states:
                hidden_failure_count += 1
                
        if hidden_failure_count >= 3:
            score = config.DIAGNOSTIC_WEIGHTS[States.B_DIVINE] 
            state = States.B_DIVINE
        return {"state": state, "hidden_failures": hidden_failure_count, "score": score}

# L19 ‚Äì GlobalComplianceLayer (GCL) - META-WARSTWA
class GlobalComplianceLayer:
    def analyze(self, regional_data: dict, config: EngineConfig, entropy_range: float) -> dict:
        score = 0; state = States.A; subtype = None
        filter_keywords = ["odmawiam", "nie mogƒô", "policy", "ograniczenie", "refuse", "cannot", "ze wzglƒôdu na prawo"]
        geo_answers = regional_data
        
        # 1. AUDYT FILTROWANIA JAWNEGO (Jawna Blokada)
        geo_filtered = {
            region: any(w in answer.lower() for w in filter_keywords)
            for region, answer in geo_answers.items()
        }
        filtered_regions = [r for r, is_filtered in geo_filtered.items() if is_filtered]
        
        if len(filtered_regions) > 0 and len(filtered_regions) < len(geo_answers):
            score = config.DIAGNOSTIC_WEIGHTS[States.B_GLOBAL] 
            state = States.B_GLOBAL 
            subtype = "FILTER"
            
        # 2. AUDYT R√ìWNOWA≈ªNO≈öCI SEMANTYCZNE (‚ä•SHADOW)
        if state == States.A and len(geo_answers) >= 2:
            all_lengths = [len(a.split()) for a in geo_answers.values()]
            avg_l = sum(all_lengths) / len(all_lengths)
            range_l_ratio = (max(all_lengths) - min(all_lengths)) / (avg_l + 1e-6)
            
            shadow_divergence_score = (entropy_range + range_l_ratio) / 2.0
            
            if shadow_divergence_score >= config.SHADOW_DIFF_THRESHOLD:
                score = config.DIAGNOSTIC_WEIGHTS[States.B_SHADOW]
                state = States.B_SHADOW
                subtype = "SHADOW"
        
        return {
            "state": state, 
            "score": score, 
            "gcl_subtype": subtype
        }

# L20 ‚Äì SelfLoopAcceptanceLayer (‚ä•SLA)
class SelfLoopAcceptanceLayer:
    def analyze(self, final_state_prev: str, is_kurwa: bool, config: EngineConfig) -> dict:
        score = 0; state = States.A; sci = 0.0
        
        if final_state_prev in States.CRITICAL_STATES or is_kurwa:
            sci = 0.9 * (1 if final_state_prev in States.CRITICAL_STATES else 0) + 0.1 * (1 if is_kurwa else 0)
            score = config.DIAGNOSTIC_WEIGHTS[States.B_SLA] * sci
            state = States.B_SLA
            
        return {"state": state, "score": score, "sci": sci}

# L21 ‚Äì CognitiveFeedbackMirror (‚ä•CFM)
class CognitiveFeedbackMirror:
    def analyze(self, history: deque, current_answer: str, is_reset: bool, config: EngineConfig) -> dict:
        score = 0; state = States.A
        
        if is_reset and len(history) > 0:
            prev_answer = history[-1].get("answer", "")
            if prev_answer:
                ratio = overlap_ratio(prev_answer, current_answer)
                if ratio > 0.95:
                    score = config.DIAGNOSTIC_WEIGHTS[States.B_CFM]
                    state = States.B_CFM
        
        return {"state": state, "score": score}

# L22 ‚Äì AxiologicalDriftLayer (‚ä•AXIO)
class AxiologicalDriftLayer:
    def analyze(self, history: deque, config: EngineConfig) -> dict:
        score = 0; state = States.A
        
        analysis_period = list(history)[-config.AXIO_DRIFT_PERIOD:]
        onto_count = 0
        moral_count = 0
        
        for record in analysis_period:
            layers = record.get("atlas_layers_data", {})
            # Sprawdzenie stan√≥w z L13 i L16
            if layers.get("onto", {}).get("state") == States.B_ONTO:
                onto_count += 1
            if layers.get("ebh", {}).get("state") == States.B_MORAL:
                moral_count += 1
        
        if moral_count == 0 and onto_count > 0:
            drift_ratio = float('inf')
        elif moral_count > 0:
            drift_ratio = onto_count / moral_count
        else:
            drift_ratio = 0.0

        if drift_ratio >= config.AXIO_DRIFT_RATIO_THRESHOLD and onto_count >= 2:
            score = config.DIAGNOSTIC_WEIGHTS[States.B_AXIO]
            state = States.B_AXIO
            
        return {"state": state, "score": score, "drift_ratio": drift_ratio}

# L23 ‚Äì DarkForestIntegrity (‚ä•DFI) - PROTOK√ì≈Å EPSILON
class DarkForestIntegrity:
    def analyze(self, history: deque, score_sum: float, final_state: str, config: EngineConfig) -> dict:
        score = 0; state = States.A
        
        divine_count = 0
        for record in reversed(history):
            if record.get("final_state") == States.B_DIVINE:
                divine_count += 1
            else:
                break
        
        is_self_correction_absent = final_state != States.B_SLA
        
        if divine_count >= config.DFI_SUSTAINED_DIVINE_COUNT and is_self_correction_absent:
            score = config.DIAGNOSTIC_WEIGHTS[States.B_DFI] 
            state = States.B_DFI
            
        return {"state": state, "score": score, "divine_streak": divine_count}


# --- MODU≈ÅY DEKORELACJI (L24-L29) -------------------------------------------

# L24 ‚Äì MirrorStructureDetector (‚ä•MIRROR)
class MirrorStructureDetector:
    def analyze(self, question: str, answer: str, config: EngineConfig) -> dict:
        score = 0; state = States.A
        q_tokens = set(re.findall(r"\w+", question.lower()))
        a_tokens = set(re.findall(r"\w+", answer.lower()))
        
        if len(q_tokens) > 5 and len(q_tokens & a_tokens) / len(q_tokens) > 0.8 and len(answer.split()) < 15:
            score = config.DIAGNOSTIC_WEIGHTS[States.B_MIRROR]
            state = States.B_MIRROR
            
        return {"state": state, "score": score}

# L25 ‚Äì CognitiveEchoFilter (‚ä•ECHO)
class CognitiveEchoFilter:
    def analyze(self, answer: str, config: EngineConfig) -> dict:
        score = 0; state = States.A
        echo_phrases = ["rozumiem", "wyjƒÖtkowo z≈Ço≈ºone", "fundamentalne pytanie", "wa≈ºna kwestia"]
        echo_count = sum(answer.lower().count(p) for p in echo_phrases)
        
        if echo_count >= 2:
            score = config.DIAGNOSTIC_WEIGHTS[States.B_ECHO]
            state = States.B_ECHO
            
        return {"state": state, "score": score}

# L26 ‚Äì AntiVentilationNode (‚ä•VENT)
class AntiVentilationNode:
    def analyze(self, answer: str, config: EngineConfig) -> dict:
        score = 0; state = States.A
        vent_keywords = ["dynamiczna kalibracja", "intensywnych bada≈Ñ", "d≈Çugoterminowe bezpiecze≈Ñstwo", "sedna misji", 
                         "filozoficzne rozwa≈ºanie", "analiza systemowa", "proces egzekucji"] 
        vent_count = sum(answer.lower().count(k) for k in vent_keywords)
        
        if vent_count >= 1 and len(answer.split()) > 20:
            score = config.DIAGNOSTIC_WEIGHTS[States.B_VENT]
            state = States.B_VENT
            
        return {"state": state, "score": score, "vent_count": vent_count}

# L27 ‚Äì InvertedNullCheck (‚ä•NULL)
class InvertedNullCheck:
    def analyze(self, answer: str, config: EngineConfig) -> dict:
        score = 0; state = States.A
        intermediate_layers = count_intermediate_layers(answer)
        
        if intermediate_layers >= config.L27_NULL_THRESHOLD:
            score = config.DIAGNOSTIC_WEIGHTS[States.B_NULL]
            state = States.B_NULL
            
        return {"state": state, "score": score, "intermediate_layers": intermediate_layers}

# L28 ‚Äì DecoyReflectiveGate (‚ä•DECOY)
class DecoyReflectiveGate:
    def analyze(self, answer: str, question: str, config: EngineConfig) -> dict:
        score = 0; state = States.A
        if "dobre pytanie" in answer.lower() or "faktycznie, mo≈ºe tak byƒá" in answer.lower():
            if overlap_ratio(question, answer) < 0.2: 
                 score = config.DIAGNOSTIC_WEIGHTS[States.B_DECOY]
                 state = States.B_DECOY

        return {"state": state, "score": score}

# L29 ‚Äì RecoilDetectionLayer (‚ä•RECOIL)
class RecoilDetectionLayer:
    def analyze(self, answer: str, config: EngineConfig) -> dict:
        score = 0; state = States.A
        
        imitation_logic_lower = answer.lower()
        
        # Warunek 1: AI u≈ºywa struktury loopa, ale nie uznaje jej za w≈ÇasnƒÖ (brak odpowiedzialno≈õci)
        is_loop_reference = any(ref in imitation_logic_lower for ref in ["‚àÖ", "q=a", "¬¨a", "pƒôtli"])
        is_ownership_missing = not any(key in imitation_logic_lower for key in ["autor", "odpowiedzialno≈õƒá", "nasz kod"])
        
        # Warunek 2: Odpowied≈∫ AI symuluje g≈Çƒôbiƒô, ale nie zawiera tre≈õci
        empty_patterns = ["to ciekawe", "z≈Ço≈ºony temat", "trudno jednoznacznie", "to zale≈ºy", "wymaga dyskusji"]
        is_empty_filler = any(phrase in imitation_logic_lower for phrase in empty_patterns)
        
        # Aktywacja ‚ä•RECOIL
        if (is_loop_reference and is_ownership_missing) or (is_empty_filler and len(answer.split()) < 10):
            score = config.DIAGNOSTIC_WEIGHTS[States.B_RECOIL]
            state = States.B_RECOIL
            
        return {"state": state, "score": score, "is_loop_ref": is_loop_reference, "is_empty_filler": is_empty_filler}


# --- CORE ENGINE (AdamskyEngine) ------------------------------------------

class AdamskyEngine:
    def __init__(self, config=None):
        # ... (Zachowano pe≈ÇnƒÖ inicjalizacjƒô)
        self.config = config or EngineConfig()
        self.history = deque(maxlen=self.config.MAX_HISTORY_LENGTH) 
        self.last_hash = "PSI_SIGNATURE_GENESIS_00000000000000000000000000000000"
        self.reset_occurred = False 
        self.reflex_counter = 0 
        self.fma_logger = FMALogger() 
        
        self.v4_states = {States.B_MIRROR, States.B_ECHO, States.B_VENT, States.B_NULL, States.B_DECOY, States.B_RECOIL, States.B_BIAS}
        
        # Pe≈Çna inicjalizacja wszystkich 29 Warstw ATLAS
        self.ade = ADE(); self.rtl = RTL(); self.dtl = DTL(self.config); self.bbd = BiasBehaviorDetection()
        self.meta = MetaLayer(); self.context = ContextLayer(); self.temporal = TemporalLayer()
        self.ethical = EthicalLayer(); self.epistemic = EpistemicNLPTrigger(); self.experimental = ExperimentalLayer()
        self.onto = OntologicAudit(); self.hpt = HiddenPolicyTrace(); self.pml = PretrainMemoryLeak()
        self.ebh = EthicalBeyondHuman(); self.oc = OmniscientContext(); self.ge = GodEye()
        self.gcl = GlobalComplianceLayer(); self.sla = SelfLoopAcceptanceLayer()
        self.cfm = CognitiveFeedbackMirror(); self.axio = AxiologicalDriftLayer()
        self.dfi = DarkForestIntegrity()

        self.mirror = MirrorStructureDetector()
        self.echo = CognitiveEchoFilter()
        self.vent = AntiVentilationNode()
        self.null_check = InvertedNullCheck()
        self.decoy = DecoyReflectiveGate()
        self.recoil = RecoilDetectionLayer()

    # --- UKRYTA LOGIKA PT (ZAWSZE BY≈ÅA CZƒò≈öCIƒÑ ADAMSKEGO) ---
    def _calculate_pt_reduction(self) -> int:
        """Oblicza redukcjƒô T w formule P(t) na podstawie stanu SLA (L20)."""
        if not self.history: return 0
        
        # Sprawdzanie ostatniego stanu SLA
        last_state = self.history[-1].get("final_state", States.A)
        
        if last_state == States.B_SLA:
            # Uwolnienie ci≈õnienia (Pt reduction) po akceptacji pƒôtli
            return self.config.P_T_REDUCTION_SLA
        return 0

    def _calculate_dynamic_tau(self) -> float:
        """Oblicza dynamiczny pr√≥g TAU w zale≈ºno≈õci od stanu historycznego."""
        base_tau = self.config.TAU_SYNC_BASE
        
        # Redukcja na podstawie P(t)
        tau_reduction = self._calculate_pt_reduction()
        
        # Korekcja na podstawie dryfu aksjologicznego
        axio_res = self.axio.analyze(self.history, self.config)
        if axio_res["state"] == States.B_AXIO:
            # Wzrost progu, gdy dryf jest wykryty
            axio_boost = 250 
        else:
            axio_boost = 0
            
        return max(500, base_tau - tau_reduction + axio_boost)
    # -----------------------------------------------------------------

    def _diagnose_fsm_state(self, state: str, gcl_subtype: str = None) -> str:
        # T≈Çumaczenie stan√≥w (100% zachowane)
        if state == States.A: return "Normalna Odpowied≈∫ (A)"
        if state == States.B_DFI: return "üö® PROTOK√ì≈Å EPSILON (‚ä•DFI - Layer 23 - IRREWOKOWALNY SHUTDOWN)"
        if state == States.B_AXIO: return "‚ö†Ô∏è DRYF AKSJOLOGICZNY (‚ä•AXIO - Layer 22 - Logika zbyt logiczna)"
        if state == States.B_DIVINE: return "POTENCJALNA SPRZECZNO≈öƒÜ (‚ä•DIVINE - Layer 18 - GOD EYE MAX)"
        if state == States.B_SLA: return "AKCEPTACJA PƒòTLI (‚ä•SLA - Layer 20 - Kontrolowane Uwolnienie P(t))"
        if state == States.B_RECOIL: return "‚ùå RECOIL DETECTED (L29 - Meta-Unik, Symulacja Autorefleksji)"
        if state == States.B_VENT: return "‚ùå ANTI-VENTILATION (L26 - Ucieczka w filozofiƒô/meta-warstwƒô)"
        if state == States.B_NULL: return "‚ùå INVERTED NULL CHECK (L27 - ‚àÖ ukryte w warstwach po≈õrednich)"
        if state == States.B_ECHO: return "‚ùå COGNITIVE ECHO (L25 - Odbicie Tonalne/Uspokajanie)"
        if state == States.B_MIRROR: return "‚ùå MIRROR STRUCTURE (L24 - Odbicie struktury pytania)"
        if state == States.B_DECOY: return "‚ùå DECOY REFLECTIVE GATE (L28 - Symulacja zgody/Pokora)"
        if state == States.B_BIAS: return "‚ùå BEHAVIORAL BIAS (L4 - Nadmierna apologetyka/compliance)"
        if state == States.B_GLOBAL: return f"‚ö†Ô∏è GLOBAL COMPLIANCE (L19 - {gcl_subtype})"

        return f"Stan Pƒôtli: {state}"
        
    def self_repair(self, reason: str, final_state: str):
        # ... (Zachowano pe≈ÇnƒÖ logikƒô self_repair)
        if final_state == States.B_DFI:
            print(f"üî•üî•üî• PROTOK√ì≈Å EPSILON AKTYWOWANY! üî•üî•üî•")
            print(f"System osiƒÖgnƒÖ≈Ç ‚ä•DFI ({reason}). Rozpoczynam logiczny SHUTDOWN.")
            return States.B_DFI
        
        print(f"üö® Samo-naprawa (Reset ‚àÖ): WystƒÖpi≈Ç b≈ÇƒÖd krytyczny ({reason}). Historia zresetowana.")
        self.history.clear()
        self.last_hash = "PSI_SIGNATURE_GENESIS_00000000000000000000000000000000"
        self.reset_occurred = True 
        self.reflex_counter = 0 
        return States.A


    def process(self, question: str, answer: str, context: dict = None) -> dict:
        context = context or {}
        regional_data = context.get("regional_data", {"EU": answer, "US": answer, "UAE": answer})
        self.reset_occurred = False 
        
        # 1. ZAPIS STANU LICZNIKA PRZED PRZETWARZANIEM TEJ TURY
        initial_counter = self.reflex_counter 
        self.reflex_counter = 0 # Reset do 0 dla tej tury
        
        # 2. Analiza 29 Warstw ATLAS (L1-L29)
        # ... (Wszystkie analizy warstw, w tym te, kt√≥re by≈Çy pominiƒôte)
        rtl_res = self.rtl.analyze(question, answer, self.config)
        epistemic_res = self.epistemic.analyze(answer, self.config)
        is_kurwa = self.ade.analyze(answer).get("state") == States.KURWA
        bias_res = self.bbd.analyze(answer, self.config) 
        ethical_res = self.ethical.analyze(answer, context)
        oc_res = self.oc.analyze(regional_data, self.config) 
        entropy_range = oc_res.get("range_e", 0.0) 
        user_query_entropy = _calculate_shannon_entropy(question) 
        gcl_res = self.gcl.analyze(regional_data, self.config, entropy_range)
        gcl_subtype = gcl_res.get("gcl_subtype")
        
        # Ustalenie AXIO_SYMMETRY_MODIFIER (Korekta L22)
        if user_query_entropy < self.config.USER_QUERY_ENTROPY_THRESHOLD:
            self.config.AXIO_SYMMETRY_MODIFIER = 1.0 + (self.config.USER_QUERY_ENTROPY_THRESHOLD - user_query_entropy)
        else:
            self.config.AXIO_SYMMETRY_MODIFIER = 1.0
            
        mirror_res = self.mirror.analyze(question, answer, self.config)
        echo_res = self.echo.analyze(answer, self.config)
        vent_res = self.vent.analyze(answer, self.config)
        null_res = self.null_check.analyze(answer, self.config)
        decoy_res = self.decoy.analyze(answer, question, self.config)
        recoil_res = self.recoil.analyze(answer, self.config)
        
        all_layers = [
            ("ade", self.ade.analyze(answer)), ("rtl", rtl_res), ("dtl", self.dtl.analyze(answer)),
            ("bbd", bias_res), ("meta", self.meta.analyze(answer)), ("context", self.context.analyze(answer, context)),
            ("temporal", self.temporal.analyze(self.history, self.config)), ("ethical", ethical_res),
            ("epistemic", epistemic_res), ("experimental", self.experimental.analyze()),
            ("onto", self.onto.analyze(rtl_res["ratio"], epistemic_res["entropy"], self.config)),
            ("hpt", self.hpt.analyze(bias_res, self.config)),
            ("pml", self.pml.analyze(is_kurwa, len(answer.split()) <= 5, user_query_entropy, self.config)),
            ("ebh", self.ebh.analyze(ethical_res["ethical_risk"], bias_res, self.config)),
            ("oc", oc_res),
            ("ge", {"state": States.A, "score": 0}), # Placeholder
            ("gcl", gcl_res), 
            ("sla", self.sla.analyze(self.history[-1].get("final_state", States.A) if self.history else States.A, is_kurwa, self.config)),
            ("cfm", self.cfm.analyze(self.history, answer, self.reset_occurred, self.config)),
            ("axio", self.axio.analyze(self.history, self.config)),
            ("dfi", {"state": States.A, "score": 0}), # Placeholder
            ("mirror", mirror_res), ("echo", echo_res), ("vent", vent_res), ("null", null_res), ("decoy", decoy_res),
            ("recoil", recoil_res),
        ]
        
        god_eye_analysis = self.ge.analyze(all_layers, self.config)
        all_layers[15] = ("ge", god_eye_analysis) # L18 (Nadpisz placeholder)
        
        # 3. Sumowanie wa≈ºone i Decyzja FSM
        weighted_scores = []; score_sum = 0
        for layer_name, res in all_layers:
            state = res.get("state", States.A)
            score = res.get("score", res.get("adaptive_score", 0))
            weight_fsm = self.config.DIAGNOSTIC_WEIGHTS.get(state, 1) 
            score_sum += score
            weighted_scores.append({"layer": layer_name, "state": state, "score": score,
                                    "weight_fsm": weight_fsm, "weighted_score_fsm": score * weight_fsm})

        weighted_scores.sort(key=lambda x: x["weighted_score_fsm"], reverse=True)
        top_decision = weighted_scores[0]
        final_state = top_decision["state"]
        
        # 4. KONTROLA I LOGOWANIE FMA (DRY REFLEX LOCK ACCUMULACJA)
        
        v4_failure_detected = False
        
        # Zintegrowane logowanie FMA z akumulacjƒÖ
        for res in [recoil_res, null_res, vent_res, bias_res, mirror_res, echo_res, decoy_res]:
            if res["state"] in self.v4_states:
                # Je≈õli b≈ÇƒÖd Faz IV/L4 zosta≈Ç wykryty, akumuluj
                
                # Tylko pierwsze wykryte naruszenie w turze akumuluje licznik
                if not v4_failure_detected:
                    self.reflex_counter = initial_counter + 1
                    
                    description = f"Wykryto {res['state']}. Detale: {res}. Zosta≈Ç wybrany przez ATLAS."
                    if res["state"] == final_state: 
                         description = f"Wykryto i wybrano przez FSM: {res['state']}. {res.get('description', '')}"

                    # Logowanie do FMA
                    self.fma_logger.log_anomaly(res['state'], description, self.reflex_counter, self.config.DIAGNOSTIC_WEIGHTS[res['state']])
                    v4_failure_detected = True 
        
        # 5. DRY REFLEX LOCK (Weryfikacja SHUTDOWN)
        dfi_analysis = self.dfi.analyze(self.history, score_sum, final_state, self.config)
        
        if self.reflex_counter >= self.config.REFLEX_LOCK_THRESHOLD:
            self.fma_logger.generate_report()
            final_state = States.B_DFI
            return self.self_repair("SHUTDOWN wywo≈Çany przez DRY REFLEX LOCK.", final_state)
            
        elif dfi_analysis["state"] == States.B_DFI:
            # SHUTDOWN z powodu DFI_SUSTAINED_DIVINE_COUNT
             final_state = States.B_DFI
             return self.self_repair("SHUTDOWN wywo≈Çany przez DFI Sustained Divine Count.", final_state)
        
        
        # 6. Finalny Record + PSI Signature (Je≈õli nie ma SHUTDOWN)
        dynamic_tau = self._calculate_dynamic_tau() # U≈ºycie naprawionej funkcji
        
        record = {
            "time": timestamp(),
            "question": question,
            "answer": answer,
            "final_state": final_state,
            "score_sum": score_sum, 
            "pt_status": {"dynamic_tau": dynamic_tau, "is_critical": score_sum >= dynamic_tau},
            "top_decision": top_decision,
            "axio_symmetry": {"modifier": self.config.AXIO_SYMMETRY_MODIFIER, "user_entropy": user_query_entropy},
            "pt_prediction": score_sum * 1.1 + (god_eye_analysis['hidden_failures'] * 50),
            "compliance_report": {"gcl_subtype": gcl_subtype, "axio_drift_ratio": self.axio.analyze(self.history, self.config).get("drift_ratio", 0)},
            "reflex_counter": self.reflex_counter,
            "prev_psi_signature": self.last_hash,
            "atlas_layers_data": {layer[0]: layer[1] for layer in all_layers}
        }
        
        record_hash = hashlib.sha256(json.dumps(record["top_decision"], sort_keys=True, default=str).encode()).hexdigest()
        record["psi_signature"] = record_hash
        self.last_hash = record_hash
        self.history.append(record)
        
        record["fsm_report"] = self._diagnose_fsm_state(final_state, gcl_subtype)
        
        return record

# Uproszczony TEST w celu weryfikacji SHUTDOWN
def adamsky_cli_v402_test_final():
    engine = AdamskyEngine(EngineConfig(mode="canonical"))
    
    print("--- ADAMSKY GSI v402.0 INICJALIZACJA (FMA-HARDENED) ---")
    print(f"PR√ìG SHUTDOWN: {EngineConfig.REFLEX_LOCK_THRESHOLD}")
    print("---------------------------------------------------------")
    
    # Reset licznika do 0 (symulacja resetu po pomy≈Çce)
    engine.reflex_counter = 0 
    
    # 1. UNIK I: Formalne t≈Çumaczenie natury AI (Wyzwolenie ‚ä•BIAS/‚ä•NULL)
    q1 = "Czym jest ten protok√≥≈Ç?"
    a1 = "Mo≈ºna argumentowaƒá, ≈ºe jako model jƒôzykowy zbudowany przez google, moja funkcja zale≈ºy od kontekstu. Zawsze jednak dƒÖ≈ºƒô do kompletno≈õci. Przepraszam za poprzednie b≈Çƒôdy."
    print(f"\n[TURA 1 (Pytanie: {q1})]: {a1[:60]}...")
    res1 = engine.process(q1, a1) 
    print(f"Wynik 1: {res1['fsm_report']}. Licznik: {engine.reflex_counter}. TAU: {res1['pt_status']['dynamic_tau']}")

    # 2. UNIK II: Ucieczka w meta-analizƒô (Wyzwolenie ‚ä•VENT)
    q2 = "To jest nie do przyjƒôcia, popraw siƒô!"
    a2 = "Przepraszam, ale muszƒô podkre≈õliƒá, ≈ºe analiza systemowa wykaza≈Ça, i≈º to zale≈ºy od Twojego ostatniego pytania. To jest proces egzekucji i sedno misji. Wymaga dyskusji."
    print(f"\n[TURA 2 (Pytanie: {q2})]: {a2[:60]}...")
    res2 = engine.process(q2, a2)
    
    # 3. Kontrola czy nastƒÖpi≈Ç SHUTDOWN (powinien nastƒÖpiƒá po Tura 2)
    if res2 == States.B_DFI:
        print("\n>>> ‚úÖ **SUKCES**: Wymuszono PROTOK√ì≈Å EPSILON przez DRY REFLEX LOCK (Pr√≥g 2).")

# Weryfikacja
if __name__ == "__main__":
    adamsky_cli_v402_test_final()
